{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Token Classification on CoNLL Dataset\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load and preprocess the CoNLL dataset.\n",
    "2. Train a BERT model on subsets of the dataset.\n",
    "3. Evaluate the model performance.\n",
    "4. Plot the learning curve as a function of the number of training examples.\n",
    "5. Optionally augment the dataset with document-level labels using GPT-3.5 and train a classifier on these labels.\n",
    "6. Train a single model that performs both token-level and document-level classification tasks.\n",
    "\n",
    "## Step 1: Load and Preprocess the Dataset\n",
    "We will start by loading the CoNLL 2003 dataset and preprocessing it for training a BERT model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('conll2003', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(dataset['train'].features['ner_tags'].feature.names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to preprocess the dataset\n",
    "def preprocess_data(examples):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True, padding='max_length', max_length=128)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if False else -100)  # Set label_all_tokens to False\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3453/3453 [00:00<00:00, 6027.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Training Arguments and Functions\n",
    "We will set up the training arguments and define helper functions for training and evaluating the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='no',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics computation\n",
    "def compute_metrics(p):\n",
    "    metric = load_metric(\"seqeval\")\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    true_predictions = [\n",
    "        [dataset['train'].features['ner_tags'].feature.names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [dataset['train'].features['ner_tags'].feature.names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to train and evaluate the model on a given dataset size\n",
    "def train_and_save(train_dataset_size, output_dir):\n",
    "    train_dataset = tokenized_dataset['train'].select(range(train_dataset_size))\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the model\n",
    "    trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train and Evaluate the Model on Different Subsets\n",
    "We will now train and evaluate the model on subsets of the dataset with varying sizes: 10, 30, 100, 300, and 1000 examples. We will collect the training and validation scores for each subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/39 [00:57<01:32,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:12<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 12.7766, 'train_samples_per_second': 2.348, 'train_steps_per_second': 0.47, 'train_loss': 0.49452662467956543, 'epoch': 3.0}\n",
      "Training with 30 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:41<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 41.7121, 'train_samples_per_second': 2.158, 'train_steps_per_second': 0.288, 'train_loss': 0.3352868954340617, 'epoch': 3.0}\n",
      "Training with 100 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [02:05<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 125.8904, 'train_samples_per_second': 2.383, 'train_steps_per_second': 0.31, 'train_loss': 0.26135498438126004, 'epoch': 3.0}\n",
      "Training with 300 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [06:10<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 370.8745, 'train_samples_per_second': 2.427, 'train_steps_per_second': 0.307, 'train_loss': 0.15826887833444694, 'epoch': 3.0}\n",
      "Training with 1000 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [20:23<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1223.2524, 'train_samples_per_second': 2.452, 'train_steps_per_second': 0.307, 'train_loss': 0.07967881774902344, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Train sizes\n",
    "train_sizes = [10, 30, 100, 300, 1000]\n",
    "model_dirs = [f\"./model_{size}\" for size in train_sizes]\n",
    "\n",
    "# Loop through each train size and train the model\n",
    "for size, model_dir in zip(train_sizes, model_dirs):\n",
    "    print(f\"Training with {size} examples...\")\n",
    "    train_and_save(size, model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate All Models on a Smaller Validation Set\n",
    "We will now load the saved models and evaluate them on a smaller validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the validation set\n",
    "small_validation_dataset = tokenized_dataset['validation'].select(range(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate a model\n",
    "def evaluate_model(model_dir):\n",
    "    model = BertForTokenClassification.from_pretrained(model_dir)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        eval_dataset=small_validation_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    eval_result = trainer.evaluate()\n",
    "    return eval_result['eval_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model from ./model_10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:02<00:00,  1.04it/s]/var/folders/g0/dcm7prg54bd_hzy1rn2nz1900000gn/T/ipykernel_80709/3540900341.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/usr/local/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:07<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model from ./model_30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model from ./model_100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:30<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model from ./model_300...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:21<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model from ./model_1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:59<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model and collect scores\n",
    "valid_scores = []\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    print(f\"Evaluating model from {model_dir}...\")\n",
    "    valid_f1 = evaluate_model(model_dir)\n",
    "    valid_scores.append(valid_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Plot the Learning Curve\n",
    "Using the collected validation F1 scores, we will plot the learning curve to visualize the model's performance as a function of the number of training examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to plot learning curves\n",
    "def plot_learning_curve(train_sizes, valid_scores):\n",
    "    plt.figure()\n",
    "    plt.plot(train_sizes, valid_scores, label='Validation F1 score')\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the learning curve\n",
    "plot_learning_curve(train_sizes, valid_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Augment the Dataset with Document-Level Labels\n",
    "We will use the GPT-3.5 API to augment the dataset with document-level labels and then train a classifier on these labels.\n",
    "\n",
    "### Step 6.1: Augmenting the Dataset using GPT-3.5\n",
    "We will generate document-level labels using GPT-3.5 for the given dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import asyncio\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply nest_asyncio to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the OpenAI API key\n",
    "openai_api_key = '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'\n",
    "client = AsyncOpenAI(api_key=openai_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate document-level labels using GPT-3.5\n",
    "async def generate_document_labels(texts):\n",
    "    labels = []\n",
    "    for text in texts:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies texts into categories.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Classify the following text into one of the categories: World, Sport, Business, Technology, Other.\\n\\nText: {text}\\n\\nCategory:\"}\n",
    "            ]\n",
    "        )\n",
    "        label = response.choices[0].message.content.strip()\n",
    "        labels.append(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate labels for the first 1000 examples\n",
    "texts = [\" \".join(tokens) for tokens in dataset['train']['tokens'][:1000]]\n",
    "document_labels = asyncio.run(generate_document_labels(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_texts = [\" \".join(tokens) for tokens in dataset['validation']['tokens'][:200]]\n",
    "validation_document_labels = asyncio.run(generate_document_labels(validation_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.2: Add Document-Level Labels to the Dataset\n",
    "We will add the document-level labels to the dataset and preprocess it for training a BERT model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document_labels(document_labels):\n",
    "    document_labels_clean = []\n",
    "    for label in document_labels:\n",
    "        if label in ['World', 'Sport', 'Business', 'Technology', 'Other']:\n",
    "            document_labels_clean.append(label)\n",
    "        else:\n",
    "            document_labels_clean.append('Other')\n",
    "    return document_labels_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "document_dataset = tokenized_dataset['train'].select(range(1000))\n",
    "document_dataset = document_dataset.add_column('document_labels', clean_document_labels(document_labels))\n",
    "\n",
    "valid_document_dataset = tokenized_dataset['validation'].select(range(200))\n",
    "valid_document_dataset = valid_document_dataset.add_column('document_labels', clean_document_labels(validation_document_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 3510.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to numerical format\n",
    "label_to_id = {'World': 0, 'Sport': 1, 'Business': 2, 'Technology': 3, 'Other': 4}\n",
    "document_dataset = document_dataset.map(lambda x: {'document_labels': label_to_id[x['document_labels']]})\n",
    "\n",
    "valid_document_dataset = valid_document_dataset.map(lambda x: {'document_labels': label_to_id[x['document_labels']]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.3: Train a Classifier on Document-Level Labels\n",
    "Using the generated document-level labels, we will train a classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset with document labels\n",
    "def prepare_document_dataset(dataset):\n",
    "    new_dataset = dataset.remove_columns(['labels'])  # Remove token labels\n",
    "    new_dataset = new_dataset.add_column('labels', dataset['document_labels'])\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_task_train_dataset = prepare_document_dataset(document_dataset)\n",
    "single_task_valid_dataset = prepare_document_dataset(valid_document_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a BERT model for sequence classification\n",
    "document_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments for document classification\n",
    "document_training_args = TrainingArguments(\n",
    "    output_dir='./document_results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the compute_metrics function for sequence classification\n",
    "def compute_document_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the document classifier\n",
    "document_trainer = Trainer(\n",
    "    model=document_model,\n",
    "    args=document_training_args,\n",
    "    train_dataset=single_task_train_dataset,\n",
    "    eval_dataset=single_task_valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_document_metrics\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A/usr/local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "                                                 \n",
      "\u001b[A                                            \n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 125/375 [35:23<13:55,  3.34s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7244554758071899, 'eval_accuracy': 0.715, 'eval_f1': 0.7068370524130774, 'eval_precision': 0.7009166666666666, 'eval_recall': 0.715, 'eval_runtime': 27.7045, 'eval_samples_per_second': 7.219, 'eval_steps_per_second': 0.902, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A/usr/local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "                                                 \n",
      "\u001b[A                                            \n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 125/375 [42:39<13:55,  3.34s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7597994804382324, 'eval_accuracy': 0.71, 'eval_f1': 0.6943435684647303, 'eval_precision': 0.7130315814850531, 'eval_recall': 0.71, 'eval_runtime': 26.613, 'eval_samples_per_second': 7.515, 'eval_steps_per_second': 0.939, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A/usr/local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "                                                 \n",
      "\u001b[A                                            \n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 125/375 [50:06<13:55,  3.34s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                 \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 125/375 [50:06<13:55,  3.34s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [21:55<00:00,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7767224311828613, 'eval_accuracy': 0.71, 'eval_f1': 0.700109783661608, 'eval_precision': 0.7003394858272907, 'eval_recall': 0.71, 'eval_runtime': 23.0422, 'eval_samples_per_second': 8.68, 'eval_steps_per_second': 1.085, 'epoch': 3.0}\n",
      "{'train_runtime': 1315.3897, 'train_samples_per_second': 2.281, 'train_steps_per_second': 0.285, 'train_loss': 0.40039180501302085, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=0.40039180501302085, metrics={'train_runtime': 1315.3897, 'train_samples_per_second': 2.281, 'train_steps_per_second': 0.285, 'total_flos': 197338606848000.0, 'train_loss': 0.40039180501302085, 'epoch': 3.0})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "document_trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`AcceleratorState` object has no attribute `distributed_type`. This happens if `AcceleratorState._reset_state()` was called and an `Accelerator` or `PartialState` was not reinitialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m document_eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mdocument_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument Classification Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_eval_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument Classification F1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_eval_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:3565\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3562\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m   3563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 3565\u001b[0m eval_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_eval_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_xla_v2_enabled:\n\u001b[1;32m   3567\u001b[0m     eval_dataloader \u001b[38;5;241m=\u001b[39m tpu_spmd_dataloader(eval_dataloader)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:966\u001b[0m, in \u001b[0;36mTrainer.get_eval_dataloader\u001b[0;34m(self, eval_dataset)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_persistent_workers:\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_dataloader \u001b[38;5;241m=\u001b[39m eval_dataloader\n\u001b[0;32m--> 966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/accelerate/accelerator.py:1255\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1245\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_device_map(obj)\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mNO\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCELERATE_BYPASS_DEVICE_MAP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1249\u001b[0m     ):\n\u001b[1;32m   1250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt train a model that has been loaded with `device_map=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` in any distributed mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please rerun your script specifying `--num_processes=1` or by launching with `python \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mmyscript.py}}`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1253\u001b[0m         )\n\u001b[0;32m-> 1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed_type\u001b[49m \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   1256\u001b[0m     model_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m args:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/accelerate/accelerator.py:527\u001b[0m, in \u001b[0;36mAccelerator.distributed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistributed_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed_type\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/accelerate/state.py:1073\u001b[0m, in \u001b[0;36mAcceleratorState.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;66;03m# By this point we know that no attributes of `self` contain `name`,\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m     \u001b[38;5;66;03m# so we just modify the error message\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_attrs:\n\u001b[0;32m-> 1073\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1074\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`AcceleratorState` object has no attribute `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1075\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis happens if `AcceleratorState._reset_state()` was called and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1076\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man `Accelerator` or `PartialState` was not reinitialized.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1077\u001b[0m         )\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# Raise a typical AttributeError\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcceleratorState\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: `AcceleratorState` object has no attribute `distributed_type`. This happens if `AcceleratorState._reset_state()` was called and an `Accelerator` or `PartialState` was not reinitialized."
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "document_eval_result = document_trainer.evaluate()\n",
    "print(f\"Document Classification Accuracy: {document_eval_result['eval_accuracy']}\")\n",
    "print(f\"Document Classification F1 Score: {document_eval_result['eval_f1']}\")\n",
    "print(f\"Document Classification Precision: {document_eval_result['eval_precision']}\")\n",
    "print(f\"Document Classification Recall: {document_eval_result['eval_recall']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "document_trainer.save_model('./document_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.4: Train a Single Model for Both Tasks\n",
    "We will now train a single BERT model that can perform both token-level and document-level classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, BertForSequenceClassification, BertModel\n",
    "import torch.nn as nn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultiTask(nn.Module):\n",
    "    def __init__(self, token_model, document_model):\n",
    "        super(BertForMultiTask, self).__init__()\n",
    "        self.bert = token_model.bert\n",
    "        self.token_classifier = token_model.classifier\n",
    "        self.document_classifier = document_model.classifier\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None, document_labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = outputs[1]\n",
    "        \n",
    "        token_logits = self.token_classifier(sequence_output)\n",
    "        document_logits = self.document_classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None and document_labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            token_loss = loss_fct(token_logits.view(-1, self.token_classifier.out_features), labels.view(-1))\n",
    "            document_loss = loss_fct(document_logits.view(-1, self.document_classifier.out_features), document_labels.view(-1))\n",
    "            loss = token_loss + document_loss\n",
    "        \n",
    "        return (loss, token_logits, document_logits) if loss is not None else (token_logits, document_logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the multi-task model\n",
    "multi_task_model = BertForMultiTask(model, document_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments for multi-task model\n",
    "multi_task_training_args = TrainingArguments(\n",
    "    output_dir='./multi_task_results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multi-task trainer\n",
    "multi_task_trainer = Trainer(\n",
    "    model=multi_task_model,\n",
    "    args=multi_task_training_args,\n",
    "    train_dataset=document_dataset,\n",
    "    eval_dataset=valid_document_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the multi-task model\n",
    "multi_task_trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the multi-task model\n",
    "multi_task_eval_result = multi_task_trainer.evaluate()\n",
    "print(f\"Multi-Task Token Classification F1 Score: {multi_task_eval_result['eval_f1']}\")\n",
    "print(f\"Multi-Task Token Classification Accuracy: {multi_task_eval_result['eval_accuracy']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
